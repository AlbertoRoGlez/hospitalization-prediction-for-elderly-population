{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler, power_transform\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "def lower(word:str):\n",
    "    print(word.lower())\n",
    "\n",
    "def unique_values(database ,label:str):\n",
    "    \n",
    "    label = label.lower()\n",
    "    n_obs = database.shape[0]\n",
    "    nunique_label = database[label].nunique()\n",
    "\n",
    "    print(f\"n° unique values is {nunique_label} of {n_obs}\")\n",
    "\n",
    "def clean_cardinality(df):\n",
    "    \n",
    "    \"\"\"Drops all columns with high and low cardinality\"\"\"\n",
    "    n_unique_values = df.nunique()\n",
    "\n",
    "    high = n_unique_values[n_unique_values == df.shape[0]].index\n",
    "    low = n_unique_values[n_unique_values == 1 ].index\n",
    "    total = [*high, *low]\n",
    "\n",
    "    df.drop(columns=total, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def clean_missing(df, threshold=0.3):\n",
    "    \n",
    "    \"\"\"drops all columns above a certain threshold\"\"\"\n",
    "\n",
    "    # mysterious treatment.\n",
    "    #df[\"DAYS_EMPLOYED\"].replace({365243: np.nan}, inplace=True)\n",
    "\n",
    "    # now, my treatment\n",
    "    nulls = df.isnull().sum()/df.shape[0]\n",
    "    #nulls.sort_values(ascending=False, inplace=True)\n",
    "    null_columns = list(nulls[nulls>=threshold].index)\n",
    "    df.drop(columns = null_columns, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def drop_correlated_features(X, threshold=0.5):\n",
    "\n",
    "    \"\"\"Find correlated columns in a DataFrame and drop them \n",
    "    \n",
    "    Arguments:\n",
    "        df (DataFrame): Data to analize.\n",
    "        threshold (float): Minimun correlation value considered to decide whether\n",
    "        two columns are correlated or not.\n",
    "     \n",
    "    Rreturns:\n",
    "        A list with non-correlated columns.\"\"\"\n",
    "    \n",
    "    numeric_features = list(X.select_dtypes(include=['int', 'float']).columns)\n",
    "    numeric_data= X[numeric_features].copy()\n",
    "    # Creating correlation matrix and getting their absolute values.\n",
    "    corr = numeric_data.corr().abs()\n",
    "    # Select upper triangle of correlation matrix\n",
    "    upper = corr.where(np.triu(np.ones(corr.shape, dtype=bool), k=1))\n",
    "    # Find features with correlation greater than 0.95\n",
    "    the_drop = [column for column in upper.columns if any(upper[column] >= threshold)]\n",
    "\n",
    "    no_correlated_columns = list(numeric_data.drop(the_drop, axis=1).columns)\n",
    "\n",
    "    return no_correlated_columns\n",
    "\n",
    "def get_features(X, type:str, get=\"all\"):\n",
    "\n",
    "    \"\"\"Extract categorical or numeric features from a DataFrame\n",
    "\n",
    "    Arguments:\n",
    "        df (dataframe): Data to analize\n",
    "        type (str): {\"c, \"n\"} Whether the desired features is categorical(c)\n",
    "                    or numeric(n).\n",
    "        get (str): Whether extract only binary, no binary or all \n",
    "        categorical features {\"all\", \"binary\", \"no_binary\"}\n",
    "        \n",
    "    Return:\n",
    "     list of all, binary or no binary categorical features.\n",
    "    \"\"\"\n",
    "    if type==\"c\":\n",
    "        # getting a table with only categorical features an their n° of unique values.\n",
    "        cat_feat = X.select_dtypes(include=['O']).nunique()\n",
    "\n",
    "        # from the object features: filtering the binary features.\n",
    "        bin_cat_feat = cat_feat[cat_feat == 2].index\n",
    "        # from the object features: filtering the non-binary features.\n",
    "        no_bin_cat_feat = cat_feat[cat_feat != 2].index\n",
    "\n",
    "        if get==\"all\":\n",
    "            col = list(cat_feat.index)\n",
    "        elif get==\"binary\":\n",
    "            col= list(bin_cat_feat)\n",
    "        elif get==\"no_binary\":\n",
    "            col=list(no_bin_cat_feat)\n",
    "        else:\n",
    "            raise Exception(\"'get' must be in {all, binary, no_binary}\")\n",
    "    elif type ==\"n\":\n",
    "        # getting the names of the numerical features\n",
    "        num_feat = X.select_dtypes(include=['int', 'float']).nunique()\n",
    "\n",
    "        if get==\"all\":\n",
    "            col = list(num_feat.index)\n",
    "        elif get==\"binary\":\n",
    "            bin_num_feat = num_feat[num_feat==2].index\n",
    "            col= list(bin_num_feat)\n",
    "        elif get==\"no_binary\":\n",
    "            no_bin_num_feat = num_feat[num_feat!=2].index\n",
    "            col=list(no_bin_num_feat)\n",
    "        else:\n",
    "            raise Exception(\"'get' must be in {all, binary, no_binary}\")\n",
    "    else:\n",
    "        raise Exception(\"'type' must be in {c, n}\")\n",
    "    \n",
    "    return col\n",
    "\n",
    "\n",
    "def val_col(df, columns_to_select):\n",
    "    valid_columns = [column for column in columns_to_select if column in df.columns]\n",
    "    return valid_columns\n",
    "\n",
    "def sel(df, columns_to_select):\n",
    "    col = val_col(df, columns_to_select)\n",
    "    return df[col]\n",
    "\n",
    "\n",
    "def preprocess_no_bin(X_train, X_test, strategy):\n",
    "    if strategy == \"simple\":\n",
    "        si = SimpleImputer(strategy='median')\n",
    "        si.fit(X_test)\n",
    "        X_test = si.transform(X_test)\n",
    "        X_train = si.transform(X_train)\n",
    "    elif strategy == \"knn\":\n",
    "        knn = KNNImputer(n_neighbors=8)\n",
    "        knn.fit(X_test)\n",
    "        X_test = knn.transform(X_test)\n",
    "        X_train = knn.transform(X_train)    \n",
    "\n",
    "\n",
    "    ss = StandardScaler()\n",
    "    ss.fit(X_test)\n",
    "    X_test=ss.transform(X_test)\n",
    "    X_train=ss.transform(X_train)\n",
    "\n",
    "    X_test = power_transform(X_test, method='yeo-johnson')\n",
    "    X_train = power_transform(X_train, method='yeo-johnson')\n",
    "\n",
    "    return X_train, X_test\n",
    "\n",
    "def preprocess_bin(X_train, X_test):\n",
    "\n",
    "    si = SimpleImputer(strategy='most_frequent')\n",
    "    si.fit(X_test)\n",
    "    X_test = si.transform(X_test)\n",
    "    X_train = si.transform(X_train)\n",
    "\n",
    "    return X_train, X_test\n",
    "\n",
    "def preprocess(df, w):\n",
    "    target = f\"r{w}hosp1y\"\n",
    "\n",
    "    #print(f\"n° features original data: {w1.shape[1]}\")\n",
    "    no_corr_columns = drop_correlated_features(df, threshold=0.4)\n",
    "    w1_no_correlated = df[no_corr_columns].copy()\n",
    "    #print(f\"n° features after drop_correlated: {w1_no_correlated.shape[1]}\")\n",
    "    w1_clean= clean_cardinality(w1_no_correlated)\n",
    "    #print(f\"n° features after clean_missing & clean_cardinality: {w1_clean.shape[1]}\")\n",
    "    # dropping the nans in the target values by row-wise\n",
    "    w1_clean.dropna(subset=[target], inplace=True)\n",
    "    #print(w1_clean.shape)\n",
    "\n",
    "    X = w1_clean.drop(columns=target).copy()\n",
    "    y = w1_clean[target].copy()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    num_bin = get_features(X_train, \"n\", 'binary')\n",
    "    #X_train_num_bin = X_train[num_bin]\n",
    "\n",
    "    num_no_bin = get_features(X_train, \"n\", 'no_binary')\n",
    "    #X_train_num_no_bin = X_train[num_no_bin]\n",
    "\n",
    "    ################# nothing here ######################\n",
    "    X_train_cat_bin = get_features(X_train, \"c\", 'binary') # nothing\n",
    "    X_train_cat_no_bin = get_features(X_train, \"c\", 'no_binary') # nothing\n",
    "\n",
    "    X_train[num_no_bin], X_test[num_no_bin] = preprocess_no_bin(X_train[num_no_bin], X_test[num_no_bin], strategy=\"simple\")\n",
    "    X_train[num_bin], X_test[num_bin] = preprocess_bin(X_train[num_bin], X_test[num_bin])\n",
    "\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "    X_test, y_test = smote.fit_resample(X_test, y_test)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = pd.read_csv(\"data/waves_norm/wave1_norm.csv\")\n",
    "w2 = pd.read_csv(\"data/waves_norm/wave2_norm.csv\")\n",
    "w3 = pd.read_csv(\"data/waves_norm/wave3_norm.csv\")\n",
    "w4 = pd.read_csv(\"data/waves_norm/wave4_norm.csv\")\n",
    "w5 = pd.read_csv(\"data/waves_norm/wave5_norm.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1, X_test_1, y_train_1, y_test_1 = preprocess(w1, 1)\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = preprocess(w2, 2)\n",
    "X_train_3, X_test_3, y_train_3, y_test_3 = preprocess(w3, 3)\n",
    "X_train_4, X_test_4, y_train_4, y_test_4 = preprocess(w4, 4)\n",
    "X_train_5, X_test_5, y_train_5, y_test_5 = preprocess(w5, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "cw1 = class_weight.compute_sample_weight(class_weight='balanced', y=y_train_1)\n",
    "cw2 = class_weight.compute_sample_weight(class_weight='balanced', y=y_train_2)\n",
    "cw3 = class_weight.compute_sample_weight(class_weight='balanced', y=y_train_3)\n",
    "cw4 = class_weight.compute_sample_weight(class_weight='balanced', y=y_train_4)\n",
    "cw5 = class_weight.compute_sample_weight(class_weight='balanced', y=y_train_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the target variable temporal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r1hosp1y\n",
      "0.0    0.5\n",
      "1.0    0.5\n",
      "Name: proportion, dtype: float64\n",
      "r2hosp1y\n",
      "0.0    0.5\n",
      "1.0    0.5\n",
      "Name: proportion, dtype: float64\n",
      "r3hosp1y\n",
      "0.0    0.5\n",
      "1.0    0.5\n",
      "Name: proportion, dtype: float64\n",
      "r4hosp1y\n",
      "0.0    0.5\n",
      "1.0    0.5\n",
      "Name: proportion, dtype: float64\n",
      "r5hosp1y\n",
      "0.0    0.5\n",
      "1.0    0.5\n",
      "Name: proportion, dtype: float64\n",
      "====================================================================================================\n",
      "r1hosp1y\n",
      "0.0    0.5\n",
      "1.0    0.5\n",
      "Name: proportion, dtype: float64\n",
      "r2hosp1y\n",
      "0.0    0.5\n",
      "1.0    0.5\n",
      "Name: proportion, dtype: float64\n",
      "r3hosp1y\n",
      "0.0    0.5\n",
      "1.0    0.5\n",
      "Name: proportion, dtype: float64\n",
      "r4hosp1y\n",
      "0.0    0.5\n",
      "1.0    0.5\n",
      "Name: proportion, dtype: float64\n",
      "r5hosp1y\n",
      "0.0    0.5\n",
      "1.0    0.5\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "y_train_list =[y_train_1, y_train_2, y_train_3, y_train_4, y_train_5]\n",
    "y_test_list = [y_test_1, y_test_2, y_test_3, y_test_4, y_test_5]\n",
    "\n",
    "for i in y_train_list:\n",
    "    print(round(i.value_counts(normalize=True), 2))\n",
    "\n",
    "print(\"=\"*100)\n",
    "\n",
    "for i in y_test_list:\n",
    "    print(round(i.value_counts(normalize=True), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "\n",
    "def logistic_reg(X_train, y_train, w_0, w_1):\n",
    "    log = LogisticRegression(random_state=42, \n",
    "                            max_iter=1000, \n",
    "                            n_jobs=-1, \n",
    "                            class_weight={0: w_0, 1: w_1})\n",
    "    return log.fit(X_train, y_train)\n",
    "\n",
    "def random_forest(X_train, y_train):\n",
    "    rf = RandomForestClassifier(n_estimators=100,\n",
    "                                random_state=42, \n",
    "                                n_jobs=-1)\n",
    "    return rf.fit(X_train, y_train)\n",
    "\n",
    "def get_performance(model, X_train, X_test, y_train, y_test):\n",
    "      y_pred = model.predict(X_test)\n",
    "\n",
    "      roc_auc_train = roc_auc_score(y_train, model.predict(X_train))\n",
    "      # Validation ROC AUC Score\n",
    "      acc = accuracy_score(y_test, y_pred)\n",
    "      roc_auc_val = roc_auc_score(y_test, y_pred)\n",
    "      print( f\"Model Accuracy: {acc}\",\n",
    "            f\"Train roc_auc: {roc_auc_train}\", \n",
    "            f\"Test roc_auc: {roc_auc_val}\",\n",
    "            sep='\\n', end='\\n\\n')\n",
    "      print(confusion_matrix(y_test, y_pred),\n",
    "      classification_report(y_test, y_pred),\n",
    "      sep='\\n')\n",
    "\n",
    "def proba_dist(model, X_test):\n",
    "    with plt.style.context('fivethirtyeight'):\n",
    "        sns.histplot(model.predict_proba(X_test), bins=50)\n",
    "        plt.title(\"Probability distribution for each Target category\")\n",
    "        plt.xlabel(\"Probability\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.7241442767758557\n",
      "Train roc_auc: 0.7817402407880335\n",
      "Test roc_auc: 0.7241442767758557\n",
      "\n",
      "[[2090  627]\n",
      " [ 872 1845]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.77      0.74      2717\n",
      "         1.0       0.75      0.68      0.71      2717\n",
      "\n",
      "    accuracy                           0.72      5434\n",
      "   macro avg       0.73      0.72      0.72      5434\n",
      "weighted avg       0.73      0.72      0.72      5434\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_1 = logistic_reg(X_train_1, y_train_1, 0.5, 0.5)\n",
    "get_performance(lr_1, X_train_1, X_test_1, y_train_1, y_test_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.9344865660655134\n",
      "Train roc_auc: 1.0\n",
      "Test roc_auc: 0.9344865660655133\n",
      "\n",
      "[[2625   92]\n",
      " [ 264 2453]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.97      0.94      2717\n",
      "         1.0       0.96      0.90      0.93      2717\n",
      "\n",
      "    accuracy                           0.93      5434\n",
      "   macro avg       0.94      0.93      0.93      5434\n",
      "weighted avg       0.94      0.93      0.93      5434\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_1 = random_forest(X_train_1, y_train_1)\n",
    "get_performance(rf_1, X_train_1, X_test_1, y_train_1, y_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgbm = XGBClassifier()\n",
    "\n",
    "xgb_model_1=xgbm.fit(X_train_1, y_train_1)\n",
    "xgb_model_2=xgbm.fit(X_train_2, y_train_2)\n",
    "xgb_model_3=xgbm.fit(X_train_3, y_train_3)\n",
    "xgb_model_4=xgbm.fit(X_train_4, y_train_4)\n",
    "\n",
    "#models = [xgb_model_1, xgb_model_2, xgb_model_3, xgb_model_4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BaggingClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                          callbacks=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None,\n",
       "                                          early_stopping_rounds=None,\n",
       "                                          enable_categorical=False,\n",
       "                                          eval_metric=None, feature_types=None,\n",
       "                                          gamma=None, gpu_id=None,\n",
       "                                          grow_policy=None,\n",
       "                                          importance_type=None,\n",
       "                                          interaction_constraints=None,\n",
       "                                          learning_rate=None, max_bin=None,\n",
       "                                          max_cat_threshold=None,\n",
       "                                          max_cat_to_onehot=None,\n",
       "                                          max_delta_step=None, max_depth=None,\n",
       "                                          max_leaves=None,\n",
       "                                          min_child_weight=None, missing=nan,\n",
       "                                          monotone_constraints=None,\n",
       "                                          n_estimators=100, n_jobs=None,\n",
       "                                          num_parallel_tree=None,\n",
       "                                          predictor=None, random_state=None, ...),\n",
       "                  n_estimators=20, n_jobs=-1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BaggingClassifier</label><div class=\"sk-toggleable__content\"><pre>BaggingClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                          callbacks=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None,\n",
       "                                          early_stopping_rounds=None,\n",
       "                                          enable_categorical=False,\n",
       "                                          eval_metric=None, feature_types=None,\n",
       "                                          gamma=None, gpu_id=None,\n",
       "                                          grow_policy=None,\n",
       "                                          importance_type=None,\n",
       "                                          interaction_constraints=None,\n",
       "                                          learning_rate=None, max_bin=None,\n",
       "                                          max_cat_threshold=None,\n",
       "                                          max_cat_to_onehot=None,\n",
       "                                          max_delta_step=None, max_depth=None,\n",
       "                                          max_leaves=None,\n",
       "                                          min_child_weight=None, missing=nan,\n",
       "                                          monotone_constraints=None,\n",
       "                                          n_estimators=100, n_jobs=None,\n",
       "                                          num_parallel_tree=None,\n",
       "                                          predictor=None, random_state=None, ...),\n",
       "                  n_estimators=20, n_jobs=-1, random_state=42)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BaggingClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                          callbacks=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None,\n",
       "                                          early_stopping_rounds=None,\n",
       "                                          enable_categorical=False,\n",
       "                                          eval_metric=None, feature_types=None,\n",
       "                                          gamma=None, gpu_id=None,\n",
       "                                          grow_policy=None,\n",
       "                                          importance_type=None,\n",
       "                                          interaction_constraints=None,\n",
       "                                          learning_rate=None, max_bin=None,\n",
       "                                          max_cat_threshold=None,\n",
       "                                          max_cat_to_onehot=None,\n",
       "                                          max_delta_step=None, max_depth=None,\n",
       "                                          max_leaves=None,\n",
       "                                          min_child_weight=None, missing=nan,\n",
       "                                          monotone_constraints=None,\n",
       "                                          n_estimators=100, n_jobs=None,\n",
       "                                          num_parallel_tree=None,\n",
       "                                          predictor=None, random_state=None, ...),\n",
       "                  n_estimators=20, n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine models using BaggingClassifier\n",
    "bagging_model = BaggingClassifier(estimator=xgbm, n_estimators=20, n_jobs=-1, random_state=42)\n",
    "\n",
    "# Train the bagging model\n",
    "bagging_model.fit(X_train_5, y_train_5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.6791044776119403\n",
      "Train roc_auc: 0.9642614312425635\n",
      "Test roc_auc: 0.6791044776119404\n",
      "\n",
      "[[1109 1839]\n",
      " [  53 2895]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.38      0.54      2948\n",
      "         1.0       0.61      0.98      0.75      2948\n",
      "\n",
      "    accuracy                           0.68      5896\n",
      "   macro avg       0.78      0.68      0.65      5896\n",
      "weighted avg       0.78      0.68      0.65      5896\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_performance(bagging_model, X_train_5, X_test_5, y_train_5, y_test_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging for RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BaggingClassifier(estimator=RandomForestClassifier(n_jobs=-1, random_state=42),\n",
       "                  n_estimators=20, n_jobs=-1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BaggingClassifier</label><div class=\"sk-toggleable__content\"><pre>BaggingClassifier(estimator=RandomForestClassifier(n_jobs=-1, random_state=42),\n",
       "                  n_estimators=20, n_jobs=-1, random_state=42)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_jobs=-1, random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_jobs=-1, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BaggingClassifier(estimator=RandomForestClassifier(n_jobs=-1, random_state=42),\n",
       "                  n_estimators=20, n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfm=RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "rfm_1=rfm.fit(X_train_1, y_train_1)\n",
    "rfm_2=rfm.fit(X_train_2, y_train_2)\n",
    "rfm_3=rfm.fit(X_train_3, y_train_3)\n",
    "rfm_4=rfm.fit(X_train_4, y_train_4)\n",
    "\n",
    "b_rf =  BaggingClassifier(estimator=rfm, n_estimators=20, n_jobs=-1, random_state=42)\n",
    "b_rf.fit(X_train_5, y_train_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.923337856173677\n",
      "Train roc_auc: 0.9930732619411865\n",
      "Test roc_auc: 0.9233378561736771\n",
      "\n",
      "[[2876   72]\n",
      " [ 380 2568]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.98      0.93      2948\n",
      "         1.0       0.97      0.87      0.92      2948\n",
      "\n",
      "    accuracy                           0.92      5896\n",
      "   macro avg       0.93      0.92      0.92      5896\n",
      "weighted avg       0.93      0.92      0.92      5896\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_performance(b_rf, X_train_5, X_test_5, y_train_5, y_test_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Votting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BaggingClassifier(estimator=VotingClassifier(estimators=[(&#x27;Logistic Regression&#x27;,\n",
       "                                                          LogisticRegression(max_iter=1000)),\n",
       "                                                         (&#x27;Decision Tree&#x27;,\n",
       "                                                          DecisionTreeClassifier(random_state=42)),\n",
       "                                                         (&#x27;SVM&#x27;,\n",
       "                                                          SVC(random_state=42)),\n",
       "                                                         (&#x27;Random Forest&#x27;,\n",
       "                                                          RandomForestClassifier(n_jobs=-1,\n",
       "                                                                                 random_state=42))],\n",
       "                                             n_jobs=-1),\n",
       "                  n_estimators=20, n_jobs=-1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BaggingClassifier</label><div class=\"sk-toggleable__content\"><pre>BaggingClassifier(estimator=VotingClassifier(estimators=[(&#x27;Logistic Regression&#x27;,\n",
       "                                                          LogisticRegression(max_iter=1000)),\n",
       "                                                         (&#x27;Decision Tree&#x27;,\n",
       "                                                          DecisionTreeClassifier(random_state=42)),\n",
       "                                                         (&#x27;SVM&#x27;,\n",
       "                                                          SVC(random_state=42)),\n",
       "                                                         (&#x27;Random Forest&#x27;,\n",
       "                                                          RandomForestClassifier(n_jobs=-1,\n",
       "                                                                                 random_state=42))],\n",
       "                                             n_jobs=-1),\n",
       "                  n_estimators=20, n_jobs=-1, random_state=42)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;Logistic Regression&#x27;,\n",
       "                              LogisticRegression(max_iter=1000)),\n",
       "                             (&#x27;Decision Tree&#x27;,\n",
       "                              DecisionTreeClassifier(random_state=42)),\n",
       "                             (&#x27;SVM&#x27;, SVC(random_state=42)),\n",
       "                             (&#x27;Random Forest&#x27;,\n",
       "                              RandomForestClassifier(n_jobs=-1,\n",
       "                                                     random_state=42))],\n",
       "                 n_jobs=-1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>Logistic Regression</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>Decision Tree</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=42)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>SVM</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(random_state=42)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>Random Forest</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_jobs=-1, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BaggingClassifier(estimator=VotingClassifier(estimators=[('Logistic Regression',\n",
       "                                                          LogisticRegression(max_iter=1000)),\n",
       "                                                         ('Decision Tree',\n",
       "                                                          DecisionTreeClassifier(random_state=42)),\n",
       "                                                         ('SVM',\n",
       "                                                          SVC(random_state=42)),\n",
       "                                                         ('Random Forest',\n",
       "                                                          RandomForestClassifier(n_jobs=-1,\n",
       "                                                                                 random_state=42))],\n",
       "                                             n_jobs=-1),\n",
       "                  n_estimators=20, n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf1 = LogisticRegression(max_iter=1000)\n",
    "clf2 = DecisionTreeClassifier(random_state=42)\n",
    "clf3 = SVC(random_state=42)\n",
    "clf4 = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "classifiers = [\n",
    "    ('Logistic Regression', clf1), \n",
    "    ('Decision Tree', clf2), \n",
    "    ('SVM', clf3), \n",
    "    ('Random Forest', clf4)\n",
    "    ]\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=classifiers, voting='hard', n_jobs=-1)\n",
    "\n",
    "v1 = voting_clf.fit(X_train_1, y_train_1)\n",
    "v2 = voting_clf.fit(X_train_2, y_train_2)\n",
    "v3 = voting_clf.fit(X_train_3, y_train_3)\n",
    "v4 = voting_clf.fit(X_train_4, y_train_4)\n",
    "\n",
    "b_voting =  BaggingClassifier(estimator=voting_clf, n_estimators=20, n_jobs=-1, random_state=42)\n",
    "b_voting.fit(X_train_5, y_train_5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.8264925373134329\n",
      "Train roc_auc: 0.9671086180520143\n",
      "Test roc_auc: 0.8264925373134329\n",
      "\n",
      "[[2839  109]\n",
      " [ 914 2034]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.96      0.85      2948\n",
      "         1.0       0.95      0.69      0.80      2948\n",
      "\n",
      "    accuracy                           0.83      5896\n",
      "   macro avg       0.85      0.83      0.82      5896\n",
      "weighted avg       0.85      0.83      0.82      5896\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_performance(b_voting, X_train_5, X_test_5, y_train_5, y_test_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
