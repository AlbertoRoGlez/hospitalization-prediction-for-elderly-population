{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Current directory: c:\\Users\\Leo\\OneDrive\\Escritorio\\Final Proyect\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import __confing\n",
    "__confing.change_to_root_folder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    __confing.execute_notebook('notebooks/data_extract.ipynb')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from src import value_filler as vf\n",
    "from src import feature_selection as fs\n",
    "from src import data_procces as dp\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from src import evaluation\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error,roc_auc_score,confusion_matrix\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance(model, X: pd.DataFrame, y: pd.Series, n: int):\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    feature_names_original = list(X.columns)\n",
    "    \n",
    "    target_name = y.name  # Obtener el nombre de la columna objetivo desde la Serie y\n",
    "    \n",
    "    if target_name in feature_names_original:\n",
    "        feature_names_original.remove(target_name)\n",
    "    \n",
    "    max_importance = list(indices[:n])\n",
    "    \n",
    "    nueva_lista = [feature_names_original[i] for i in max_importance]\n",
    "    \n",
    "    return nueva_lista\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "n='a'\n",
    "df=pd.read_csv(r'data\\custom\\all_waves.csv')\n",
    "target=f'p{n}hosp1y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = ['pahosp1y','paurina2y','pacholst','pabreast','paprost','papapsm','pamammog','pacage','padrinkcr','padrinkbd','padrinkb','paheight','paweight','pabmi','papaina','papainlv','papainfr','pafatigue','pawheeze','pabreath_m','paswell','pahearaid','pahearing','pasight','paglasses','palunglmt_m','pahrtatlmt','pastroklmt','paarthlmt','palowermoba','pauppermoba','pagrossaa','palgmusaa','pamobilaa','paclims','pasit','paarms','palift','pastoop','pachair','pameals','pashop','pamoney','pameds','pabedhlp','pabed','patoilt','paeat','pabath','pawalkr','padress','pahipcomp','pafall','pafallinj','pamhip','pahipe_m','parxarthr','parxstrok','parxhrtat','pacncrothr','pacncrmeds','pacncrradn','pacncrsurg','pacncrchem','parxdiab','parxdiabo','parxhibp','parechrtatt','parifaany','parfaany','parfcaren','pararcare','padresshlp', 'pawalkhlp', 'pabathehlp', 'paeathlp', 'pabedhlp', 'patoilethlp', 'pamealhlp', 'pashophlp', 'pamedhlp', 'pamoneyhlp','pahibpe','pagender','padiabe','pacancre','palunglmt_m','parxlung_m','pahrtatte','pastroke','paarthre','parifaany','parafaany','pahigov','pasmokev','pasmoken','paoangry','paosleep','paodngr','paodngr','paopace','paoplot','paoalchl','pawthh','paagey','pamomage','padadage','paprmem','parjudg','parorgnz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = list(set(selected))\n",
    "df = df.dropna(subset=[target]) \n",
    "df = df[selected].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "porcentaje_nulos = df.isnull().sum(axis=1) / len(df.columns)\n",
    "df = df[(df[target] != 0) | (porcentaje_nulos <= 0.4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill\n",
    "y = df[target]\n",
    "X = df.drop(target,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Leo\\OneDrive\\Escritorio\\Final Proyect\\src\\feature_selection.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe[columns] = dataframe[columns].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "from src import feature_selection as fs\n",
    "X = fs.fast_fill(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split\n",
    "X_train, X_test, y_train, y_test=dp.split_data(X, y, test_size=0.2, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # resample \n",
    "X_train, y_train = dp.apply_resample(X_train, y_train,v=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smote\n",
    "X_train, y_train = dp.apply_smote(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler\n",
    "X_train, X_test = dp.apply_standard_scaler(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC=0.818907880831218\n",
      "pahosp1y\n",
      "0.0    15548\n",
      "1.0     2827\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f'AUC={auc}')\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pagrossaa', 'parifaany', 'palift', 'pashop', 'pacholst', 'pafatigue', 'paswell', 'parfcaren', 'parxhibp', 'pabreath_m', 'parxdiabo', 'pafall', 'pahrtatte', 'pararcare', 'padrinkcr', 'pahigov', 'paurina2y', 'parxdiab', 'pacncrchem', 'pafallinj', 'pawalkr', 'pahipe_m', 'pagender', 'parxlung_m', 'pabathehlp', 'paprost', 'pacncrradn', 'pacncrsurg', 'pabed', 'paeat', 'pahipcomp', 'padrinkb', 'parxhrtat', 'padiabe', 'pauppermoba', 'pacancre', 'pabath', 'pasit', 'papaina', 'parxarthr', 'papainfr', 'pamammog', 'pasmokev', 'palunglmt_m', 'pastroke', 'patoilethlp', 'palgmusaa', 'pabedhlp', 'pachair', 'pahrtatlmt', 'patoilt', 'papapsm', 'pacncrmeds', 'pawheeze', 'pamobilaa', 'pacage', 'pawalkhlp', 'pahearaid', 'pasmoken', 'pameds', 'pashophlp', 'padrinkbd', 'paarms', 'parfaany', 'pastoop']\n"
     ]
    }
   ],
   "source": [
    "print(feature_importance(model, X, y, 65))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pagrossaa', 'parifaany', 'palift', 'pashop', 'pacholst', 'pafatigue', 'paswell', 'parfcaren', 'parxhibp', 'pabreath_m', 'parxdiabo', 'pafall', 'pahrtatte', 'pararcare', 'padrinkcr', 'pahigov', 'paurina2y', 'parxdiab', 'pacncrchem', 'pafallinj', 'pawalkr', 'pahipe_m', 'pagender', 'parxlung_m', 'pabathehlp', 'paprost', 'pacncrradn', 'pacncrsurg', 'pabed', 'paeat', 'pahipcomp', 'padrinkb', 'parxhrtat', 'padiabe', 'pauppermoba', 'pacancre', 'pabath', 'pasit', 'papaina', 'parxarthr', 'papainfr', 'pamammog', 'pasmokev', 'palunglmt_m', 'pastroke', 'patoilethlp', 'palgmusaa', 'pabedhlp', 'pachair', 'pahrtatlmt', 'patoilt', 'papapsm', 'pacncrmeds', 'pawheeze', 'pamobilaa', 'pacage', 'pawalkhlp', 'pahearaid', 'pasmoken', 'pameds', 'pashophlp', 'padrinkbd', 'paarms', 'parfaany', 'pastoop', 'pastroklmt', 'padress', 'parechrtatt', 'paglasses', 'papainlv']\n"
     ]
    }
   ],
   "source": [
    "print(feature_importance(model, X, y, 70))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pagrossaa', 'parifaany', 'palift', 'pashop', 'pacholst', 'pafatigue', 'paswell', 'parfcaren', 'parxhibp', 'pabreath_m', 'parxdiabo', 'pafall', 'pahrtatte', 'pararcare', 'padrinkcr', 'pahigov', 'paurina2y', 'parxdiab', 'pacncrchem', 'pafallinj', 'pawalkr', 'pahipe_m', 'pagender', 'parxlung_m', 'pabathehlp', 'paprost', 'pacncrradn', 'pacncrsurg', 'pabed', 'paeat', 'pahipcomp', 'padrinkb', 'parxhrtat', 'padiabe', 'pauppermoba', 'pacancre', 'pabath', 'pasit', 'papaina', 'parxarthr', 'papainfr', 'pamammog', 'pasmokev', 'palunglmt_m', 'pastroke', 'patoilethlp', 'palgmusaa', 'pabedhlp', 'pachair', 'pahrtatlmt', 'patoilt', 'papapsm', 'pacncrmeds', 'pawheeze', 'pamobilaa', 'pacage', 'pawalkhlp', 'pahearaid', 'pasmoken', 'pameds', 'pashophlp', 'padrinkbd', 'paarms', 'parfaany', 'pastoop', 'pastroklmt', 'padress', 'parechrtatt', 'paglasses', 'papainlv', 'paweight', 'paclims', 'paarthre', 'paheight', 'palowermoba']\n"
     ]
    }
   ],
   "source": [
    "print(feature_importance(model, X, y, 75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pagrossaa', 'parifaany', 'palift', 'pashop', 'pacholst', 'pafatigue', 'paswell', 'parfcaren', 'parxhibp', 'pabreath_m', 'parxdiabo', 'pafall', 'pahrtatte', 'pararcare', 'padrinkcr', 'pahigov', 'paurina2y', 'parxdiab', 'pacncrchem', 'pafallinj', 'pawalkr', 'pahipe_m', 'pagender', 'parxlung_m', 'pabathehlp', 'paprost', 'pacncrradn', 'pacncrsurg', 'pabed', 'paeat', 'pahipcomp', 'padrinkb', 'parxhrtat', 'padiabe', 'pauppermoba', 'pacancre', 'pabath', 'pasit', 'papaina', 'parxarthr', 'papainfr', 'pamammog', 'pasmokev', 'palunglmt_m', 'pastroke', 'patoilethlp', 'palgmusaa', 'pabedhlp', 'pachair', 'pahrtatlmt', 'patoilt', 'papapsm', 'pacncrmeds', 'pawheeze', 'pamobilaa', 'pacage', 'pawalkhlp', 'pahearaid', 'pasmoken', 'pameds', 'pashophlp', 'padrinkbd', 'paarms', 'parfaany', 'pastoop', 'pastroklmt', 'padress', 'parechrtatt', 'paglasses', 'papainlv', 'paweight', 'paclims', 'paarthre', 'paheight', 'palowermoba', 'pawthh', 'paagey', 'pabreast', 'pabmi', 'pameals']\n"
     ]
    }
   ],
   "source": [
    "print(feature_importance(model, X, y, 80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[113], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39merror\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: error"
     ]
    }
   ],
   "source": [
    "raise ValueError('error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_dataframe(df, columnas):\n",
    "    df_suma = df[columnas].sum(axis=1)\n",
    "    df = df.drop(columns=columnas)\n",
    "    df['nueva_columna'] = np.where(df_suma != 0, 1, np.nan)\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
