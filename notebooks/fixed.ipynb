{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: c:\\Users\\Leo\\OneDrive\\Escritorio\\Final Proyect\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import __confing\n",
    "__confing.change_to_root_folder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    __confing.execute_notebook('notebooks/data_extract.ipynb')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from src import value_filler as vf\n",
    "from src import feature_selection as fs\n",
    "from src import data_procces as dp\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from src import evaluation\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error,roc_auc_score,confusion_matrix\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance(model, df:pd.DataFrame, target:str, n:int):\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    feature_names_original = list(df.columns)\n",
    "    feature_names_original.remove(target)\n",
    "    \n",
    "    max_importance = list(indices[:n])\n",
    "    \n",
    "    nueva_lista = [feature_names_original[i] for i in max_importance]\n",
    "    \n",
    "    return nueva_lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance(model, X_train, X_test, y_train, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    roc_auc_train = roc_auc_score(y_train, model.predict(X_train))\n",
    "    # Validation ROC AUC Score\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    roc_auc_val = roc_auc_score(y_test, y_pred)\n",
    "    print( f\"Model Accuracy: {acc}\",\n",
    "            f\"Train roc_auc: {roc_auc_train}\", \n",
    "            f\"Test roc_auc: {roc_auc_val}\",\n",
    "            sep='\\n', end='\\n\\n')\n",
    "    print(confusion_matrix(y_test, y_pred),\n",
    "    classification_report(y_test, y_pred),\n",
    "    sep='\\n'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n='a'\n",
    "df=pd.read_csv(r'data\\custom\\all_waves.csv')\n",
    "target=f'p{n}hosp1y'\n",
    "drop=[f'p{n}hspnit1y','paoophos1y','paoophosf1y'] # si la wave3 falla quitar estas columnas , 'r3bpsft', 'r3bpref'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop\n",
    "df = df.drop(drop, axis=1)\n",
    "\n",
    "df = df.dropna(subset=[target]) \n",
    "\n",
    "porcentaje_nulos = df.isnull().sum(axis=1) / len(df.columns)\n",
    "df = df[(df[target] != 0) | (porcentaje_nulos <= 0.3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill\n",
    "y = df[target]\n",
    "X = df.drop(target,axis=1)\n",
    "X = fs.fast_fill_2(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\n"
     ]
    }
   ],
   "source": [
    "# feature selection\n",
    "feature_selected=['padoctor1y','paurina2y','pacholst','pabreast','paprost','papapsm','pamammog','pacage','padrinkcr','padrinkbd','padrinkb','paheight','paweight','pabmi','papaina','papainlv','papainfr','pafatigue','pawheeze','pabreath_m','paswell','pahearaid','pahearing','pasight','paglasses','palunglmt_m','pahrtatlmt','pastroklmt','paarthlmt','palowermoba','pauppermoba','pagrossaa','palgmusaa','pamobilaa','paclims','pasit','paarms','palift','pastoop','pachair','pameals','pashop','pamoney','pameds','pabedhlp','pabed','patoilt','paeat','pabath','pawalkr','padress','pahipcomp','pafall','pafallinj','pamhip','pahipe_m','parxarthr','parxstrok','parxhrtat','pacncrothr','pacncrmeds','pacncrradn','pacncrsurg','pacncrchem','parxdiab','parxdiabo','parxhibp','parechrtatt','parifaany','parfaany','parfcaren','pararcare','padresshlp', 'pawalkhlp', 'pabathehlp', 'paeathlp', 'pabedhlp', 'patoilethlp', 'pamealhlp', 'pashophlp', 'pamedhlp', 'pamoneyhlp','pahibpe','pagender','padiabe','pacancre','palunglmt_m','parxlung_m','pahrtatte','pastroke','paarthre','parifaany','parafaany','pahigov','pasmokev','pasmoken','paoangry','paosleep','paodngr','paodngr','paopace','paoplot','paoalchl','pawthh','paagey','pamomage','padadage','paprmem','parjudg','parorgnz']\n",
    "X=X[feature_selected]\n",
    "print(len(feature_selected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split\n",
    "X_train, X_test, y_train, y_test=dp.split_data(X, y, test_size=0.2, random_state=40)\n",
    "X_test_o, y_test_o = X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample \n",
    "X_train, y_train = dp.apply_resample(X_train, y_train,v=1.20)\n",
    "X_test, y_test = dp.apply_resample(X_test, y_test,v=1.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smote\n",
    "X_train, y_train = dp.apply_smote(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler\n",
    "X_train, X_test = dp.apply_standard_scaler(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC=0.9668403982908357\n",
      "pahosp1y\n",
      "0.0    3528\n",
      "1.0    2940\n",
      "Name: count, dtype: int64\n",
      "\n",
      "######################################################\n",
      "\n",
      "AUC=0.8408862265707173\n",
      "pahosp1y\n",
      "1.0    2940\n",
      "0.0    1798\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def train_xgboost_with_kfold(features, labels, model):\n",
    "    k = 15\n",
    "    kf = KFold(n_splits=k)\n",
    "    \n",
    "    for train_index, test_index in kf.split(features):\n",
    "        X_train, X_test = features[train_index], features[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        \n",
    "        # Entrenar el modelo XGBoost\n",
    "        model.fit(X_train, y_train)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model_k = xgb.XGBClassifier()\n",
    "model_k= train_xgboost_with_kfold(X_train, y_train,model_k)\n",
    "\n",
    "y_pred_proba = model_k.predict_proba(X_test)[:, 1]\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f'AUC={auc}')\n",
    "print(y_test.value_counts())\n",
    "\n",
    "print('')\n",
    "print('######################################################')\n",
    "print('')\n",
    "\n",
    "y_pred_proba = model_k.predict_proba(X_test_o)[:, 1]\n",
    "auc = roc_auc_score(y_test_o, y_pred_proba)\n",
    "print(f'AUC={auc}')\n",
    "print(y_test_o.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raise ValueError('comentar el error')\n",
    "feature_selected = feature_importance(model_k, df, target, n=50)\n",
    "print(feature_selected)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
