{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Current directory: c:\\Users\\Leo\\OneDrive\\Escritorio\\Final Proyect\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import __confing\n",
    "__confing.change_to_root_folder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    __confing.execute_notebook('notebooks/data_extract.ipynb')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from src import value_filler as vf\n",
    "from src import feature_selection as fs\n",
    "from src import data_procces as dp\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from src import evaluation\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error,roc_auc_score,confusion_matrix\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def feature_importance(model, X: pd.DataFrame, y: list, n: int):\n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    feature_names_original = list(X.columns)\n",
    "    \n",
    "    max_importance = list(indices[:n])\n",
    "    \n",
    "    nueva_lista = [feature_names_original[i] for i in max_importance]\n",
    "    \n",
    "    return nueva_lista\n",
    "\n",
    "\n",
    "def get_performance(model, X_train, X_test, y_train, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    roc_auc_train = roc_auc_score(y_train, model.predict(X_train))\n",
    "    # Validation ROC AUC Score\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    roc_auc_val = roc_auc_score(y_test, y_pred)\n",
    "    print( f\"Model Accuracy: {acc}\",\n",
    "            f\"Train roc_auc: {roc_auc_train}\", \n",
    "            f\"Test roc_auc: {roc_auc_val}\",\n",
    "            sep='\\n', end='\\n\\n')\n",
    "    print(confusion_matrix(y_test, y_pred),\n",
    "    classification_report(y_test, y_pred),\n",
    "    sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "n='a'\n",
    "df=pd.read_csv(r'data\\custom\\all_waves.csv')\n",
    "target=f'p{n}hosp1y'\n",
    "drop=[f'p{n}hspnit1y','paoophos1y','paoophosf1y'] # si la wave3 falla quitar estas columnas , 'r3bpsft', 'r3bpref'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop\n",
    "df = df.drop(drop, axis=1)\n",
    "\n",
    "df = df.dropna(subset=[target]) \n",
    "\n",
    "porcentaje_nulos = df.isnull().sum(axis=1) / len(df.columns)\n",
    "df = df[(df[target] != 0) | (porcentaje_nulos <= 0.4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill\n",
    "y = df[target]\n",
    "X1 = df.drop(target,axis=1)\n",
    "X1 = fs.fast_fill_2(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\n"
     ]
    }
   ],
   "source": [
    "# feature selection\n",
    "feature_selected=['padoctor1y','paurina2y','pacholst','pabreast','paprost','papapsm','pamammog','pacage','padrinkcr','padrinkbd','padrinkb','paheight','paweight','pabmi','papaina','papainlv','papainfr','pafatigue','pawheeze','pabreath_m','paswell','pahearaid','pahearing','pasight','paglasses','palunglmt_m','pahrtatlmt','pastroklmt','paarthlmt','palowermoba','pauppermoba','pagrossaa','palgmusaa','pamobilaa','paclims','pasit','paarms','palift','pastoop','pachair','pameals','pashop','pamoney','pameds','pabedhlp','pabed','patoilt','paeat','pabath','pawalkr','padress','pahipcomp','pafall','pafallinj','pamhip','pahipe_m','parxarthr','parxstrok','parxhrtat','pacncrothr','pacncrmeds','pacncrradn','pacncrsurg','pacncrchem','parxdiab','parxdiabo','parxhibp','parechrtatt','parifaany','parfaany','parfcaren','pararcare','padresshlp', 'pawalkhlp', 'pabathehlp', 'paeathlp', 'pabedhlp', 'patoilethlp', 'pamealhlp', 'pashophlp', 'pamedhlp', 'pamoneyhlp','pahibpe','pagender','padiabe','pacancre','palunglmt_m','parxlung_m','pahrtatte','pastroke','paarthre','parifaany','parafaany','pahigov','pasmokev','pasmoken','paoangry','paosleep','paodngr','paodngr','paopace','paoplot','paoalchl','pawthh','paagey','pamomage','padadage','paprmem','parjudg','parorgnz']\n",
    "X=X1[feature_selected]\n",
    "print(len(feature_selected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split\n",
    "X_train, X_test, y_train, y_test=dp.split_data(X, y, test_size=0.2, random_state=40)\n",
    "X_test_o, y_test_o = X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample \n",
    "X_train, y_train = dp.apply_resample(X_train, y_train,v=1.20)\n",
    "X_test, y_test = dp.apply_resample(X_test, y_test,v=1.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smote\n",
    "X_train, y_train = dp.apply_smote(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler\n",
    "X_train, X_test = dp.apply_standard_scaler(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC=0.9069899923198053\n",
      "pahosp1y\n",
      "0.0    3506\n",
      "1.0    2922\n",
      "Name: count, dtype: int64\n",
      "\n",
      "######################################################\n",
      "\n",
      "AUC=0.8097103309031835\n",
      "pahosp1y\n",
      "0.0    5679\n",
      "1.0    2922\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def train_xgboost_with_kfold(features, labels, model):\n",
    "    k = 8\n",
    "    kf = KFold(n_splits=k)\n",
    "    \n",
    "    for train_index, test_index in kf.split(features):\n",
    "        X_train, X_test = features[train_index], features[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        \n",
    "        # Entrenar el modelo XGBoost\n",
    "        model.fit(X_train, y_train)\n",
    "    \n",
    "    return model\n",
    "\n",
    "model_k = xgb.XGBClassifier()\n",
    "model_k= train_xgboost_with_kfold(X_train, y_train,model_k)\n",
    "\n",
    "y_pred_proba = model_k.predict_proba(X_test)[:, 1]\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f'AUC={auc}')\n",
    "print(y_test.value_counts())\n",
    "\n",
    "print('')\n",
    "print('######################################################')\n",
    "print('')\n",
    "\n",
    "y_pred_proba = model_k.predict_proba(X_test_o)[:, 1]\n",
    "auc = roc_auc_score(y_test_o, y_pred_proba)\n",
    "print(f'AUC={auc}')\n",
    "print(y_test_o.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "list.remove(x): x not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# raise ValueError('comentar el error')\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m fs \u001b[39m=\u001b[39m feature_importance(model_k, X, target, n\u001b[39m=\u001b[39;49m\u001b[39m65\u001b[39;49m)\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(fs)\n",
      "Cell \u001b[1;32mIn[70], line 6\u001b[0m, in \u001b[0;36mfeature_importance\u001b[1;34m(model, df, target, n)\u001b[0m\n\u001b[0;32m      3\u001b[0m indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margsort(importances)[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m      5\u001b[0m feature_names_original \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(df\u001b[39m.\u001b[39mcolumns)\n\u001b[1;32m----> 6\u001b[0m feature_names_original\u001b[39m.\u001b[39;49mremove(target)\n\u001b[0;32m      8\u001b[0m max_importance \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(indices[:n])\n\u001b[0;32m     10\u001b[0m nueva_lista \u001b[39m=\u001b[39m [feature_names_original[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m max_importance]\n",
      "\u001b[1;31mValueError\u001b[0m: list.remove(x): x not in list"
     ]
    }
   ],
   "source": [
    "# raise ValueError('comentar el error')\n",
    "fs = feature_importance(model_k, X, target, n=65)\n",
    "print(fs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
